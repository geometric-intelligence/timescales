{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Binary Counter Task Analysis\n",
        "\n",
        "This notebook analyzes a MultiTimescaleRNN trained on the hierarchical binary counter task.\n",
        "\n",
        "**Contents:**\n",
        "1. Load trained model\n",
        "2. Training & validation loss curves\n",
        "3. Ground truth vs. predictions visualization\n",
        "4. 3D PCA of hidden state activations\n",
        "5. Learned timescale distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "from rnns.multitimescale_rnn import MultiTimescaleRNN\n",
        "from datamodules.binary_counter import HierarchicalCounterDataModule\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the path to your trained model directory\n",
        "MODEL_DIR = Path(\"../logs/single_runs/multitimescale_YYYYMMDD_HHMMSS\")  # <-- UPDATE THIS\n",
        "\n",
        "# Alternatively, find the most recent binary counter run\n",
        "# runs = sorted(Path(\"../logs/single_runs\").glob(\"multitimescale_*\"), key=lambda x: x.stat().st_mtime)\n",
        "# MODEL_DIR = runs[-1]\n",
        "# print(f\"Using most recent run: {MODEL_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load config\n",
        "config_files = list(MODEL_DIR.glob(\"config_seed*.yaml\"))\n",
        "if not config_files:\n",
        "    raise FileNotFoundError(f\"No config file found in {MODEL_DIR}\")\n",
        "    \n",
        "with open(config_files[0]) as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Task:\", config.get(\"task\", \"path_integration\"))\n",
        "print(\"Config:\")\n",
        "for key in ['n_levels', 'base_flip_prob', 'noise_std', 'num_time_steps', 'hidden_size', 'activation', 'learn_timescales']:\n",
        "    if key in config:\n",
        "        print(f\"  {key}: {config[key]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model\n",
        "model_files = list(MODEL_DIR.glob(\"final_model_seed*.pth\"))\n",
        "if not model_files:\n",
        "    raise FileNotFoundError(f\"No model file found in {MODEL_DIR}\")\n",
        "\n",
        "# Reconstruct model architecture\n",
        "model = MultiTimescaleRNN(\n",
        "    input_size=config.get(\"input_size\", 1),  # Binary counter has input_size=1 by default\n",
        "    hidden_size=config[\"hidden_size\"],\n",
        "    output_size=config[\"n_levels\"],  # Output is n_levels for binary counter\n",
        "    dt=config[\"dt\"],\n",
        "    activation=getattr(nn, config[\"activation\"]),\n",
        "    learn_timescales=config[\"learn_timescales\"],\n",
        "    init_timescale=config.get(\"init_timescale\"),\n",
        "    normalize_hidden=config.get(\"normalize_hidden\", False),\n",
        "    zero_diag_wrec=config.get(\"zero_diag_wrec\", True),\n",
        ")\n",
        "\n",
        "# Load weights\n",
        "state_dict = torch.load(model_files[0], map_location=\"cpu\", weights_only=True)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded from {model_files[0]}\")\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Training & Validation Loss vs Epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load loss history\n",
        "loss_file = MODEL_DIR / \"loss_history.json\"\n",
        "\n",
        "if loss_file.exists():\n",
        "    with open(loss_file) as f:\n",
        "        loss_history = json.load(f)\n",
        "    \n",
        "    epochs = loss_history.get(\"epochs\", list(range(len(loss_history.get(\"train_loss\", [])))))\n",
        "    train_loss = loss_history.get(\"train_loss\", [])\n",
        "    val_loss = loss_history.get(\"val_loss\", [])\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "    \n",
        "    ax.plot(epochs, train_loss, label=\"Train Loss\", linewidth=2)\n",
        "    ax.plot(epochs, val_loss, label=\"Validation Loss\", linewidth=2)\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"BCE Loss\")\n",
        "    ax.set_title(\"Training & Validation Loss\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_yscale(\"log\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Final train loss: {train_loss[-1]:.4f}\")\n",
        "    print(f\"Final val loss: {val_loss[-1]:.4f}\")\n",
        "else:\n",
        "    print(f\"Loss history file not found at {loss_file}\")\n",
        "    print(\"Available files:\", list(MODEL_DIR.glob(\"*\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Ground Truth vs Predictions Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datamodule for generating test trajectories\n",
        "dm = HierarchicalCounterDataModule(\n",
        "    n_levels=config[\"n_levels\"],\n",
        "    base_flip_prob=config[\"base_flip_prob\"],\n",
        "    noise_std=config.get(\"noise_std\", 0.1),\n",
        "    num_time_steps=config[\"num_time_steps\"],\n",
        "    num_trajectories=100,  # Small number for visualization\n",
        "    batch_size=16,\n",
        "    num_workers=0,\n",
        ")\n",
        "dm.setup()\n",
        "\n",
        "print(f\"Theoretical timescales (steps): {dm.theoretical_timescales}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a batch of test data\n",
        "batch = next(iter(dm.val_dataloader()))\n",
        "inputs, states, targets = batch\n",
        "\n",
        "print(f\"Inputs shape: {inputs.shape}\")\n",
        "print(f\"Targets shape: {targets.shape}\")\n",
        "\n",
        "# Run model on test data\n",
        "with torch.no_grad():\n",
        "    hidden_states, outputs = model(inputs, init_context=None)\n",
        "    predictions = torch.sigmoid(outputs)  # Convert logits to probabilities\n",
        "\n",
        "print(f\"Hidden states shape: {hidden_states.shape}\")\n",
        "print(f\"Outputs shape: {outputs.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize ground truth vs predictions for a few example trajectories\n",
        "n_examples = 3\n",
        "n_levels = config[\"n_levels\"]\n",
        "\n",
        "fig, axes = plt.subplots(n_examples, 2, figsize=(16, 3 * n_examples), sharex=True)\n",
        "\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, n_levels))\n",
        "\n",
        "for i in range(n_examples):\n",
        "    # Left: Ground truth\n",
        "    ax_gt = axes[i, 0]\n",
        "    for level in range(n_levels):\n",
        "        offset = level * 1.2  # Vertical offset for stacking\n",
        "        ax_gt.fill_between(\n",
        "            range(targets.shape[1]),\n",
        "            offset,\n",
        "            offset + targets[i, :, level].numpy(),\n",
        "            alpha=0.7,\n",
        "            color=colors[level],\n",
        "            label=f\"Level {level} (τ≈{dm.theoretical_timescales[level]:.0f})\"\n",
        "        )\n",
        "        ax_gt.axhline(y=offset, color='gray', linestyle='--', alpha=0.3)\n",
        "    \n",
        "    ax_gt.set_ylabel(f\"Example {i+1}\")\n",
        "    ax_gt.set_yticks([level * 1.2 + 0.5 for level in range(n_levels)])\n",
        "    ax_gt.set_yticklabels([f\"s_{level}\" for level in range(n_levels)])\n",
        "    if i == 0:\n",
        "        ax_gt.set_title(\"Ground Truth States\")\n",
        "        ax_gt.legend(loc='upper right', fontsize=8)\n",
        "    \n",
        "    # Right: Predictions\n",
        "    ax_pred = axes[i, 1]\n",
        "    for level in range(n_levels):\n",
        "        offset = level * 1.2\n",
        "        ax_pred.fill_between(\n",
        "            range(predictions.shape[1]),\n",
        "            offset,\n",
        "            offset + predictions[i, :, level].numpy(),\n",
        "            alpha=0.7,\n",
        "            color=colors[level],\n",
        "        )\n",
        "        ax_pred.axhline(y=offset, color='gray', linestyle='--', alpha=0.3)\n",
        "    \n",
        "    ax_pred.set_yticks([level * 1.2 + 0.5 for level in range(n_levels)])\n",
        "    ax_pred.set_yticklabels([f\"ŝ_{level}\" for level in range(n_levels)])\n",
        "    if i == 0:\n",
        "        ax_pred.set_title(\"Model Predictions (σ(output))\")\n",
        "\n",
        "axes[-1, 0].set_xlabel(\"Time Step\")\n",
        "axes[-1, 1].set_xlabel(\"Time Step\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(MODEL_DIR / \"ground_truth_vs_predictions.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute per-level accuracy\n",
        "with torch.no_grad():\n",
        "    binary_preds = (predictions > 0.5).float()\n",
        "    \n",
        "    # Per-level accuracy\n",
        "    for level in range(n_levels):\n",
        "        acc = (binary_preds[:, :, level] == targets[:, :, level]).float().mean()\n",
        "        print(f\"Level {level} (τ≈{dm.theoretical_timescales[level]:.0f}): {acc:.4f} accuracy\")\n",
        "    \n",
        "    # Overall accuracy\n",
        "    overall_acc = (binary_preds == targets).float().mean()\n",
        "    print(f\"\\nOverall accuracy: {overall_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 3D PCA of Hidden State Activations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use more trajectories for PCA\n",
        "n_trajectories_pca = 10\n",
        "\n",
        "with torch.no_grad():\n",
        "    hidden_states_pca, _ = model(inputs[:n_trajectories_pca], init_context=None)\n",
        "\n",
        "# Reshape: [n_traj, T, hidden] -> [n_traj * T, hidden]\n",
        "n_traj, T, hidden_size = hidden_states_pca.shape\n",
        "hidden_flat = hidden_states_pca.reshape(-1, hidden_size).numpy()\n",
        "\n",
        "print(f\"Hidden states shape for PCA: {hidden_flat.shape}\")\n",
        "\n",
        "# Fit PCA\n",
        "pca = PCA(n_components=3)\n",
        "hidden_pca = pca.fit_transform(hidden_flat)\n",
        "\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
        "print(f\"Total explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reshape back to [n_traj, T, 3]\n",
        "hidden_pca_reshaped = hidden_pca.reshape(n_traj, T, 3)\n",
        "\n",
        "# Interactive 3D plot colored by time\n",
        "fig = go.Figure()\n",
        "\n",
        "for traj_idx in range(n_traj):\n",
        "    traj_data = hidden_pca_reshaped[traj_idx]\n",
        "    \n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=traj_data[:, 0],\n",
        "        y=traj_data[:, 1],\n",
        "        z=traj_data[:, 2],\n",
        "        mode='lines+markers',\n",
        "        marker=dict(\n",
        "            size=3,\n",
        "            color=np.arange(T),\n",
        "            colorscale='Viridis',\n",
        "            showscale=(traj_idx == 0),\n",
        "            colorbar=dict(title=\"Time Step\") if traj_idx == 0 else None,\n",
        "        ),\n",
        "        line=dict(width=2, color=f'rgba({50 + traj_idx*20}, {100 + traj_idx*10}, {200 - traj_idx*15}, 0.5)'),\n",
        "        name=f'Trajectory {traj_idx}',\n",
        "        hovertemplate=f'Traj {traj_idx}<br>PC1: %{{x:.2f}}<br>PC2: %{{y:.2f}}<br>PC3: %{{z:.2f}}<br>Time: %{{marker.color}}<extra></extra>'\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f'3D PCA of Hidden States ({pca.explained_variance_ratio_.sum():.1%} variance explained)',\n",
        "    scene=dict(\n",
        "        xaxis_title=f'PC1 ({pca.explained_variance_ratio_[0]:.1%})',\n",
        "        yaxis_title=f'PC2 ({pca.explained_variance_ratio_[1]:.1%})',\n",
        "        zaxis_title=f'PC3 ({pca.explained_variance_ratio_[2]:.1%})',\n",
        "    ),\n",
        "    width=900,\n",
        "    height=700,\n",
        "    showlegend=True,\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative: Color by the slowest level state (s_{K-1})\n",
        "all_pc1 = hidden_pca_reshaped[:, :, 0].flatten()\n",
        "all_pc2 = hidden_pca_reshaped[:, :, 1].flatten()\n",
        "all_pc3 = hidden_pca_reshaped[:, :, 2].flatten()\n",
        "all_states = targets[:n_traj, :, -1].numpy().flatten()\n",
        "\n",
        "fig2 = go.Figure()\n",
        "\n",
        "fig2.add_trace(go.Scatter3d(\n",
        "    x=all_pc1,\n",
        "    y=all_pc2,\n",
        "    z=all_pc3,\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=3,\n",
        "        color=all_states,\n",
        "        colorscale=[[0, 'blue'], [1, 'red']],\n",
        "        showscale=True,\n",
        "        colorbar=dict(title=f\"s_{n_levels-1}\"),\n",
        "    ),\n",
        "    hovertemplate=f'PC1: %{{x:.2f}}<br>PC2: %{{y:.2f}}<br>PC3: %{{z:.2f}}<br>s_{n_levels-1}: %{{marker.color}}<extra></extra>'\n",
        "))\n",
        "\n",
        "fig2.update_layout(\n",
        "    title=f'3D PCA Colored by Slowest Level State (s_{n_levels-1})',\n",
        "    scene=dict(\n",
        "        xaxis_title=f'PC1 ({pca.explained_variance_ratio_[0]:.1%})',\n",
        "        yaxis_title=f'PC2 ({pca.explained_variance_ratio_[1]:.1%})',\n",
        "        zaxis_title=f'PC3 ({pca.explained_variance_ratio_[2]:.1%})',\n",
        "    ),\n",
        "    width=900,\n",
        "    height=700,\n",
        ")\n",
        "\n",
        "fig2.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Learned Timescale Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get learned timescales\n",
        "if model.learn_timescales:\n",
        "    timescales = model.rnn_step.current_timescales.detach().numpy()\n",
        "    alphas = model.rnn_step.current_alphas.detach().numpy()\n",
        "    \n",
        "    print(f\"Timescale stats:\")\n",
        "    print(f\"  Min: {timescales.min():.4f} s\")\n",
        "    print(f\"  Max: {timescales.max():.4f} s\")\n",
        "    print(f\"  Mean: {timescales.mean():.4f} s\")\n",
        "    print(f\"  Std: {timescales.std():.4f} s\")\n",
        "else:\n",
        "    timescales = model.rnn_step.timescales.numpy()\n",
        "    print(\"Timescales are fixed (not learned)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot timescale histogram\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Convert theoretical timescales from steps to seconds\n",
        "dt = config[\"dt\"]\n",
        "theoretical_tau_seconds = dm.theoretical_timescales * dt\n",
        "\n",
        "# Histogram of timescales (in seconds)\n",
        "ax1 = axes[0]\n",
        "ax1.hist(timescales, bins=50, edgecolor='black', alpha=0.7)\n",
        "ax1.axvline(x=config.get(\"init_timescale\", 0.5), color='red', linestyle='--', \n",
        "            label=f\"Init τ = {config.get('init_timescale', 0.5)}s\", linewidth=2)\n",
        "\n",
        "# Add vertical lines for theoretical timescales\n",
        "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(theoretical_tau_seconds)))\n",
        "for i, (tau, c) in enumerate(zip(theoretical_tau_seconds, colors)):\n",
        "    ax1.axvline(x=tau, color=c, linestyle=':', linewidth=2,\n",
        "                label=f\"Theoretical τ_{i} = {tau:.3f}s\")\n",
        "\n",
        "ax1.set_xlabel(\"Timescale (seconds)\")\n",
        "ax1.set_ylabel(\"Count\")\n",
        "ax1.set_title(\"Learned Timescale Distribution\")\n",
        "ax1.legend(fontsize=9)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Log-scale histogram\n",
        "ax2 = axes[1]\n",
        "ax2.hist(np.log10(timescales), bins=50, edgecolor='black', alpha=0.7)\n",
        "ax2.axvline(x=np.log10(config.get(\"init_timescale\", 0.5)), color='red', linestyle='--', \n",
        "            label=f\"Init τ = {config.get('init_timescale', 0.5)}s\", linewidth=2)\n",
        "\n",
        "for i, (tau, c) in enumerate(zip(theoretical_tau_seconds, colors)):\n",
        "    ax2.axvline(x=np.log10(tau), color=c, linestyle=':', linewidth=2,\n",
        "                label=f\"Theoretical τ_{i}\")\n",
        "\n",
        "ax2.set_xlabel(\"log₁₀(Timescale) [seconds]\")\n",
        "ax2.set_ylabel(\"Count\")\n",
        "ax2.set_title(\"Learned Timescale Distribution (Log Scale)\")\n",
        "ax2.legend(fontsize=9)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(MODEL_DIR / \"learned_timescales.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare theoretical vs learned timescale coverage\n",
        "print(\"\\nTimescale Comparison:\")\n",
        "print(f\"{'Level':<8} {'Theoretical (steps)':<20} {'Theoretical (s)':<18} {'Neurons in [τ/2, 2τ]':<20}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for i, (tau_steps, tau_s) in enumerate(zip(dm.theoretical_timescales, theoretical_tau_seconds)):\n",
        "    # Find neurons with timescales closest to this theoretical value (within factor of 2)\n",
        "    in_range = (timescales > tau_s / 2) & (timescales < tau_s * 2)\n",
        "    n_in_range = in_range.sum()\n",
        "    \n",
        "    print(f\"s_{i:<6} {tau_steps:<20.0f} {tau_s:<18.4f} {n_in_range}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"BINARY COUNTER ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nModel: {MODEL_DIR.name}\")\n",
        "print(f\"Hidden size: {config['hidden_size']}\")\n",
        "print(f\"Number of levels: {config['n_levels']}\")\n",
        "print(f\"Base flip probability: {config['base_flip_prob']}\")\n",
        "print(f\"\\nTheoretical timescales (steps): {dm.theoretical_timescales}\")\n",
        "print(f\"Theoretical timescales (seconds): {theoretical_tau_seconds}\")\n",
        "print(f\"\\nLearned timescale range: [{timescales.min():.4f}, {timescales.max():.4f}] s\")\n",
        "print(f\"Learned timescale mean ± std: {timescales.mean():.4f} ± {timescales.std():.4f} s\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
